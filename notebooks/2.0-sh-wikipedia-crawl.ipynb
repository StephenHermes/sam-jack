{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to get data from the Wikipedia \"Lists of American Films\" pages. Each of these pages has a URL following the same genral pattern, and generally consists of a few similarly structured tables holding at the very least the name of a movie. \n",
    "\n",
    "There are a couple inconsistancies between the different years' pages:\n",
    "1. Movies before 1900 have a single page and are held in a single table with multi-column spans grouping the different years.\n",
    "2. Starting around 2014, there is are multi-row spans for the film's opening month: there is a tacky vertical box spelling out the month name vertically over multiple rows. Worse still the day of the month is then in a seperate column with multi-row spans, and these two columns are grouped together into a single \"Opening\" column. \n",
    "3. Other pages have tables split up by first letter of the name of the film, and don't necessarily have the same column names from table to table, even within a single year's page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<table>\n",
    "<tr><th colspan=\"2\">Opening<th>\n",
    "    <th style=\"width:20%;\">Title</th>\n",
    "    <th style=\"width:10%;\">Director</th>\n",
    "    <th>Cast</th>\n",
    "    <th style=\"width:13%\">Genre</th>\n",
    "    <th style=\"width:20%\">Notes</th>\n",
    "    <th>Ref.</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th rowspan=\"22\"><b>J<br />A<br />N<br />U<br />A<br />R<br />Y<br /></b></th>\n",
    "    <th><b>2</b></th>\n",
    "    <td><i><a href=\"/wiki/The_Woman_in_Black_2:_Angel_of_Death\" class=\"mw-redirect\" title=\"The Woman in Black 2: Angel of Death\">The Woman in Black 2: Angel of Death</a></i></td>\n",
    "    <td><a href=\"/wiki/Tom_Harper_(director)\" title=\"Tom Harper (director)\">Tom Harper</a></td>\n",
    "    <td><a href=\"/wiki/Phoebe_Fox\" title=\"Phoebe Fox\">Phoebe Fox</a><p><a href=\"/wiki/Jeremy_Irvine\" title=\"Jeremy Irvine\">Jeremy Irvine</a></p><p><a href=\"/wiki/Helen_McCrory\" title=\"Helen McCrory\">Helen McCrory</a></p><p><a href=\"/wiki/Adrian_Rawlins\" title=\"Adrian Rawlins\">Adrian Rawlins</a></p><p><a href=\"/wiki/Ned_Dennehy\" title=\"Ned Dennehy\">Ned Dennehy</a></p></td>\n",
    "    <td><a href=\"/wiki/Horror_film\" title=\"Horror film\">Horror</a></td>\n",
    "    <td><a href=\"/wiki/Relativity_Media\" title=\"Relativity Media\">Relativity Media</a><p>Sequel to <i><a href=\"/wiki/The_Woman_in_Black_(2012_film)\" title=\"The Woman in Black (2012 film)\">The Woman in Black (2012)</a></i></p></td>\n",
    "    <td></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "    <th rowspan=\"2\"><b>9</b></th> \n",
    "    <td><i><a href=\"/wiki/Taken_3\" title=\"Taken 3\">Taken 3</a></i></td>\n",
    "    <td><a href=\"/wiki/Olivier_Megaton\" title=\"Olivier Megaton\">Olivier Megaton</a></td>\n",
    "    <td><a href=\"/wiki/Liam_Neeson\" title=\"Liam Neeson\">Liam Neeson</a><p><a href=\"/wiki/Forest_Whitaker\" title=\"Forest Whitaker\">Forest Whitaker</a></p><p><a href=\"/wiki/Famke_Janssen\" title=\"Famke Janssen\">Famke Janssen</a></p><p><a href=\"/wiki/Maggie_Grace\" title=\"Maggie Grace\">Maggie Grace</a></p></td>\n",
    "    <td><a href=\"/wiki/Action_film\" title=\"Action film\">Action</a></td>\n",
    "    <td><a href=\"/wiki/20th_Century_Fox\" title=\"20th Century Fox\">20th Century Fox</a></td>\n",
    "    <td></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# Get a table to work with\n",
    "tables = soup.find_all('table') #, {'class': 'wikitable'})\n",
    "table = tables[0]\n",
    "\n",
    "# Get all rows from table, i.e., all <tr> tags\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# row of headers\n",
    "row0 = rows[0]\n",
    "# row with stupid month column\n",
    "row1 = rows[1]\n",
    "# row with stupid day column\n",
    "row2 = rows[2]\n",
    "# normalish row\n",
    "# row3 = rows[3]\n",
    "\n",
    "# Check if row is a header row and if so, build the columns.\n",
    "# Should be refactored to be more pythonic?\n",
    "# I Want list comprehensions...\n",
    "row = row0\n",
    "\n",
    "if not row.find_all('td'):\n",
    "    # If no <td> tags then a header row\n",
    "    columns = []\n",
    "    for x in row.find_all('th'):\n",
    "        colspan = int(x.attrs.pop('colspan', 1))\n",
    "        if colspan > 1:\n",
    "            columns += [f'{x.text.strip()}__{i}' for i in range(colspan)]\n",
    "        else:\n",
    "            columns += [x.text.strip()]\n",
    "\n",
    "def parse_header_row(row):\n",
    "    \"\"\"If a row is a header, run this.\"\"\"\n",
    "    columns = []\n",
    "    for x in row.find_all('th'):\n",
    "        colspan = int(x.attrs.pop('colspan', 1))\n",
    "        if colspan > 1:\n",
    "            columns += [f'{x.text.strip()}__{i}' for i in range(colspan)]\n",
    "        else:\n",
    "            columns += [x.text.strip()]\n",
    "    return columns\n",
    "            \n",
    "            \n",
    "# For entries with rowspan, save value and amount left to fill\n",
    "counters = dict((key, [0, None]) for key in columns)\n",
    "\n",
    "def parse_data_row(row, columns, counters):\n",
    "    \"\"\"If a row is not a header, run this.\"\"\"\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    cell_cursor = 0\n",
    "    row_processed = []\n",
    "\n",
    "    for col in columns:\n",
    "\n",
    "        print('cursor', cell_cursor, '\\ncolumn', col)\n",
    "        print(counters)\n",
    "\n",
    "        # Check if values to propagate\n",
    "        if counters[col][0] > 0:\n",
    "            print('in the counter if')\n",
    "            \n",
    "            cell_value = counters[col][1]\n",
    "\n",
    "            counters[col][0] -= 1   \n",
    "        # If not propagate, get from cell    \n",
    "        else:\n",
    "            cell = cells[cell_cursor]\n",
    "            rowspan = int(cell.attrs.pop('rowspan', 1))\n",
    "            cell_value = cell.text.strip()\n",
    "            print('rowspan', rowspan, '\\ncell_value', cell_value)\n",
    "\n",
    "            if rowspan > 1:\n",
    "                counters[col] = [rowspan - 1, cell_value]\n",
    "                \n",
    "            cell_cursor += 1\n",
    "\n",
    "        row_processed.append(cell_value)     \n",
    "        \n",
    "    return row_processed\n",
    "    \n",
    "\n",
    "### FOR SOME REASON THE ATTRIBUTES ARTE GETTING LOST ON MULTIPLE RUNS?!\n",
    "\n",
    "\n",
    "# row0.find_all(['th', 'td'])\n",
    "# [cell.attrs for cell in row1.find_all('th')]\n",
    "\n",
    "# if all cells have <th colspan=\"n\"> w/ n \\ge 0 then header row\n",
    "# instantiate column for each and multiple for those with colspan > 0\n",
    "\n",
    "# if at least one <th rowspan> or <td> (table data) tag, then data row\n",
    "# if rowspan > 0 then instantiate counter and set that column equal to that value for the \n",
    "#     next rowspan rows. Multiple counters should be handled ?appropriately?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_header_row(row):\n",
    "    \"\"\"If a row is a header, run this.\"\"\"\n",
    "    \n",
    "    # If exists <td> tags then not a header row\n",
    "    if row.find_all('td'):\n",
    "        raise ValueError(\"`row` is not a table header.\")\n",
    "    \n",
    "    columns = []\n",
    "    for x in row.find_all('th'):\n",
    "        colspan = int(x.attrs.pop('colspan', 1))\n",
    "        if colspan > 1:\n",
    "            columns += [f'{x.text.strip()}__{i}' for i in range(colspan)]\n",
    "        else:\n",
    "            columns += [x.text.strip()]\n",
    "    return columns\n",
    "            \n",
    "\n",
    "def _parse_data_row(row, columns, counters):\n",
    "    \"\"\"If a row is not a header, run this.\"\"\"\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    cell_cursor = 0\n",
    "    row_processed = []\n",
    "\n",
    "    for col in columns:\n",
    "        # Check if values to propagate\n",
    "        if counters[col][0] > 0:\n",
    "            cell_value = counters[col][1]\n",
    "            counters[col][0] -= 1   \n",
    "        # If not propagate, get from cell    \n",
    "        else:\n",
    "            cell = cells[cell_cursor]\n",
    "            rowspan = int(cell.attrs.pop('rowspan', 1))\n",
    "            cell_value = cell.text.strip()\n",
    "\n",
    "            if rowspan > 1:\n",
    "                counters[col] = [rowspan - 1, cell_value]\n",
    "                \n",
    "            cell_cursor += 1\n",
    "\n",
    "        row_processed.append(cell_value)     \n",
    "        \n",
    "    return row_processed\n",
    "\n",
    "\n",
    "def parse_table(table):\n",
    "    \"\"\"Parse rows of table.\"\"\"\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    header_row = rows.pop(0)\n",
    "    columns = _parse_header_row(header_row) \n",
    "    # For entries with rowspan, save value and amount left to fill        \n",
    "    counters = dict((key, [0, None]) for key in columns)\n",
    "    \n",
    "    table_parsed = []\n",
    "    for row in rows:\n",
    "        row_parsed = _parse_data_row(row, columns, counters)\n",
    "        table_parsed.append(row_parsed)\n",
    "        \n",
    "    table_parsed = pd.DataFrame(table_parsed, columns=columns)\n",
    "    return table_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opening__0</th>\n",
       "      <th>Opening__1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Ref.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>2</td>\n",
       "      <td>The Woman in Black 2: Angel of Death</td>\n",
       "      <td>Tom Harper</td>\n",
       "      <td>Phoebe Fox\\nJeremy Irvine\\nHelen McCrory\\nAdri...</td>\n",
       "      <td>Horror</td>\n",
       "      <td>Relativity Media\\nSequel to The Woman in Black...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>9</td>\n",
       "      <td>Taken 3</td>\n",
       "      <td>Olivier Megaton</td>\n",
       "      <td>Liam Neeson\\nForest Whitaker\\nFamke Janssen\\nM...</td>\n",
       "      <td>Action</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>9</td>\n",
       "      <td>Let's Kill Ward's Wife</td>\n",
       "      <td>Scott Foley</td>\n",
       "      <td>Scott FoleyPatrick WilsonDonald FaisonJames Ca...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Well Go USA Entertainment</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>14</td>\n",
       "      <td>Match</td>\n",
       "      <td>Stephen Belber</td>\n",
       "      <td>Patrick StewartCarla GuginoMatthew LillardRob ...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>IFC Films</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>16</td>\n",
       "      <td>Blackhat</td>\n",
       "      <td>Michael Mann</td>\n",
       "      <td>Chris HemsworthViola DavisManny MontanaTang Wei</td>\n",
       "      <td>Action</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Opening__0 Opening__1                                 Title  \\\n",
       "0    JANUARY          2  The Woman in Black 2: Angel of Death   \n",
       "1    JANUARY          9                               Taken 3   \n",
       "2    JANUARY          9                Let's Kill Ward's Wife   \n",
       "3    JANUARY         14                                 Match   \n",
       "4    JANUARY         16                              Blackhat   \n",
       "\n",
       "          Director                                               Cast   Genre  \\\n",
       "0       Tom Harper  Phoebe Fox\\nJeremy Irvine\\nHelen McCrory\\nAdri...  Horror   \n",
       "1  Olivier Megaton  Liam Neeson\\nForest Whitaker\\nFamke Janssen\\nM...  Action   \n",
       "2      Scott Foley  Scott FoleyPatrick WilsonDonald FaisonJames Ca...  Comedy   \n",
       "3   Stephen Belber  Patrick StewartCarla GuginoMatthew LillardRob ...   Drama   \n",
       "4     Michael Mann    Chris HemsworthViola DavisManny MontanaTang Wei  Action   \n",
       "\n",
       "                                               Notes  Ref.  \n",
       "0  Relativity Media\\nSequel to The Woman in Black...        \n",
       "1                                   20th Century Fox        \n",
       "2                          Well Go USA Entertainment  [11]  \n",
       "3                                          IFC Films  [12]  \n",
       "4                                 Universal Pictures  [13]  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://en.wikipedia.org/wiki/List_of_American_films_of_2015'\n",
    "# Get raw html\n",
    "response = requests.get(url)  \n",
    "# Soupify\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get a table to work with\n",
    "tables = soup.find_all('table', {'class': 'wikitable'})\n",
    "table = tables[0]\n",
    "\n",
    "parse_table(table).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we just need a giant list of either movie names or IMDB ids...\n",
    "\n",
    "# EVERYTHING BELOW IS OLD AND OUTDATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2. Getting a List of Movies\n",
    "\n",
    "Using `requests` we now have a way of extracting data about a film, given its title. Now all we need is a list of movies over which to iterate. After a bit of googling, I found a wikipedia page listing movies, but it is organized through several subpages. We'll use the BeautifulSoup package to crawl these pages to generate our list of movies.\n",
    "\n",
    "There are two paths of attack:\n",
    "1. `https://en.wikipedia.org/wiki/Lists_of_films` has data on every movie ever made. There are a few different hierarchies movies are classified by on this. This catalogs every movie ever made.\n",
    "2. `https://en.wikipedia.org/wiki/Lists_of_American_films` is just American films, organized by year. This is maybe easier to work with, since the organization is more orderly.\n",
    "\n",
    "Since this project is ultimately stupid, I'll just do the easier thing and use the American movie list. Additionally, the American film list is split up by year, where the different years have their own pages. The urls for these pages are very consistent, so easy to crawl. Each year's page has the movies listed in tables, which appear to always have the same columns.\n",
    "\n",
    "For this part I used this tutorial https://goo.gl/Bm1cdD (sort of).\n",
    "\n",
    "A webpage is basically a tree with nodes labeled by tags. BeautifulSoup packages this tree in an object that is easy to navigate and search, based off of the html tags attached to the nodes. Here's how we are going to pull the movie data for any given year.\n",
    "1. We pull the raw html using requests and passing the url to a `GET` request.\n",
    "2. Dump the html string into a BeautifulSoup object.\n",
    "3. From inspecting the raw html it looks like the data we want is always in a table, which we can find with the `table` tag. There are some other tables, such as the footers and page navigation that we don't want. Again from inspection, it looks like the tables we do want always have `class=wikitable`.\n",
    "4. The tables are then split into rows. A row either consitsts of headers (`th` table header tag) or data (`td` table data tag). We pull this, put it in a data frame if we actually get data, and skip if we get an error putting it into the data frame.\n",
    "\n",
    "When we first wrote the `fetch_movie_data` function below, we did not have the `drop_colspan` feature Or the 1919 correction. When it was ranon all time, there were a few problems:\n",
    "1. Starting in 2014, the movie lists have an \"Opening\" data column, whose entries span multiple rows. Even though our script didn't throw any errors for 2015 the data gathered is wrong: actors are listed as movie titles, titles are listed as opening dates, and so on. These cells have tags with colspan attributes, which are larger than 1. To fix this we added the `drop_colspan` flag, which does not include columns that span multiple cells.\n",
    "2. There is a \"typo\" on the page for 1919. The very last row of the table has an extra cell. Not sure what the best way to deal with this one edge case is. I ended up counting the number of columns read, and only take that many cells for the data rows.\n",
    "\n",
    "There are definitely better ways to handle these problems. In particular, my solution assumes the multicolumns are all up front in the table, and that the multicolumn and the 1919 typo don't coincide on any page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fetch_movie_data(url, drop_colspan=True):\n",
    "    # Get the response from GET request\n",
    "    response = requests.get(url)  \n",
    "    # Throw error if API call has an error\n",
    "    if response.status_code != 200:\n",
    "        raise requests.HTTPError(\n",
    "            f'Couldn\\'t call API. Error {response.status_code}.'\n",
    "        )\n",
    "  \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Get all tables on the site where the class is wikitable\n",
    "    # This prevents it from including layout tabes, like the wikipedia footer etc\n",
    "    tables = soup.find_all('table', {'class': 'wikitable'})\n",
    "\n",
    "    fetched = []\n",
    "    for table in tables:\n",
    "        # Get all table rows (tr) tag\n",
    "        rows = table.find_all('tr')\n",
    "        # Assuming first row is headers, look for table header (th) tags\n",
    "        if drop_colspan:\n",
    "            columns = []; drop = 0\n",
    "            for col in rows[0].find_all('th'):\n",
    "                # If has an attribute for colspan > 1, don't include\n",
    "                try:\n",
    "                    int(col.attrs['colspan']) > 1\n",
    "                    drop += int(col.attrs['colspan'])\n",
    "                except:\n",
    "                    columns.append(col.text.strip())\n",
    "        else:\n",
    "            columns = [x.text.strip() for x in rows[0].find_all('th')]\n",
    "        \n",
    "        # Assuming remaining rows are data, look for table data (td) tags\n",
    "        data = [[x.text.strip() for x in row.find_all('td')] for row in rows[1:]]\n",
    "        \n",
    "        if drop_colspan:\n",
    "            # Assuming the multicols are all in front\n",
    "            if drop > 0:\n",
    "                data = [row[-len(columns):] for row in data]\n",
    "        # Deal with error in the 1919 Wikipedia page...\n",
    "        # data = [row[:len(columns)] for row in data]\n",
    "        # Make sure we got data. \n",
    "        # If for whatever reason there is an error, don't include\n",
    "        if data and columns:\n",
    "            try:\n",
    "                df = pd.DataFrame(data, columns=columns)\n",
    "            except:\n",
    "                continue\n",
    "            fetched.append(df)\n",
    "    return pd.concat(fetched, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_1994 = fetch_movie_data('https://en.wikipedia.org/wiki/List_of_American_films_of_1952')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Notes/Studio</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Yankee Buccaneer</td>\n",
       "      <td>Frederick de Cordova</td>\n",
       "      <td>Jeff Chandler, Scott Brady, Suzan Ball</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Universal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>You for Me</td>\n",
       "      <td>Don Weis</td>\n",
       "      <td>Jane Greer, Peter Lawford</td>\n",
       "      <td>Romance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Young Man with Ideas</td>\n",
       "      <td>Mitchell Leisen</td>\n",
       "      <td>Glenn Ford, Ruth Roman</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MGM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Yukon Gold</td>\n",
       "      <td>Frank McDonald</td>\n",
       "      <td>Kirby Grant, Martha Hyer</td>\n",
       "      <td>Western</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Monogram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Zombies of the Stratosphere</td>\n",
       "      <td>Fred C. Brannon</td>\n",
       "      <td></td>\n",
       "      <td>Serial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Republic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Title              Director  \\\n",
       "91             Yankee Buccaneer  Frederick de Cordova   \n",
       "92                   You for Me              Don Weis   \n",
       "93         Young Man with Ideas       Mitchell Leisen   \n",
       "94                   Yukon Gold        Frank McDonald   \n",
       "95  Zombies of the Stratosphere       Fred C. Brannon   \n",
       "\n",
       "                                      Cast      Genre Notes/Studio      Notes  \n",
       "91  Jeff Chandler, Scott Brady, Suzan Ball  Adventure          NaN  Universal  \n",
       "92               Jane Greer, Peter Lawford    Romance          NaN        MGM  \n",
       "93                  Glenn Ford, Ruth Roman     Comedy          NaN        MGM  \n",
       "94                Kirby Grant, Martha Hyer    Western          NaN   Monogram  \n",
       "95                                             Serial          NaN   Republic  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_1994.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten things to appear to work for one year, let's creep that net. The above tutorial suggests using a timer to prevent us from sending too many requests to Wikipedia and getting blocked. I'm expecting the `fetch_movie_data` to fail sometimes, so let's collect our data in a dict. That way we can know exactly what years failed and what years we have data for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each year from 1900 to 2017\n",
    "movie_data = {}\n",
    "for year in range(1900, 2018):\n",
    "    url = f'https://en.wikipedia.org/wiki/List_of_American_films_of_{year}'\n",
    "    try:\n",
    "        data = fetch_movie_data(url)\n",
    "        movie_data[year] = data\n",
    "    except:\n",
    "        print(f'Something went wrong fetching data for {year}')\n",
    "        pass\n",
    "    # Pause for 2 sec to not overwhelm Wikipedia\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This took maybe 10 minutes to run. \n",
    "\n",
    "We really only want the title and the year, so let's get that. We could also get the cast and genre from here, but I feel like the OMDb versions of this will be more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, movies in movie_data.items():\n",
    "    movies['Year'] = year\n",
    "movies_full = pd.concat([movies[['Title', 'Year']] for movies in movie_data.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ~26K movies, which would take about 26 days to get IMDb data for using the free OMDb API. Maybe we should kick them a buck to do this faster.\n",
    "\n",
    "### 1.3. Combining Everything\n",
    "\n",
    "Note to future self: When running this we got fewer results when requesting full synopsis. The API only return results with a full synposis if requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_teh_jsons = []\n",
    "for row in movies_full.itertuples(index=False, name=None):\n",
    "    try:\n",
    "        response_json = get_movie_data(*row)\n",
    "    except:\n",
    "        # If can't find with year, don't use\n",
    "        try:\n",
    "            response_json = get_movie_data(row[0])\n",
    "        except:\n",
    "            # Continue if no data found\n",
    "            continue\n",
    "        if response_json['Plot'] != 'N/A':\n",
    "            all_teh_jsons.append(response_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
