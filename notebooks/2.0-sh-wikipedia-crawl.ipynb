{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Crawl\n",
    "\n",
    "Using the OMDb API we can pull data on a film, provided we supply the film's title. Thus, to pull ample film data from IMDb, we will need an ample list of film names. After a bit of Googling, I found a Wikipedia page listing movies, but it is organized through several subpages. We'll use the BeautifulSoup package to crawl these pages to generate our list of movies. The webcrawling approach we take here is based to some degree off of the tutorial https://goo.gl/Bm1cdD.\n",
    "\n",
    "There are two paths of attack:\n",
    "1. `https://en.wikipedia.org/wiki/Lists_of_films` has data on every movie ever made. There are a few different hierarchies movies are classified by on this. This catalogs every movie ever made.\n",
    "2. `https://en.wikipedia.org/wiki/Lists_of_American_films` is just American films, organized by year. This is easier to work with, since the organization is more orderly. Films are organized by year, and have generally similar layouts.\n",
    "\n",
    "As a starting point I'll just do the easier thing and use the American movie list. In the future if we want more training data then we can revisit getting foreign films. \n",
    "\n",
    "There are a couple inconsistancies between the different years' pages, which we will have to consider:\n",
    "1. Movies before 1900 have a single page and are held in a single table with multi-column spans grouping the different years.\n",
    "2. Starting around 2014, there is are multi-row spans for the film's opening month: there is a tacky vertical box spelling out the month name vertically over multiple rows. Worse still the day of the month is then in a seperate column with multi-row spans, and these two columns are grouped together into a single \"Opening\" column. \n",
    "3. Other pages have tables split up by first letter of the name of the film, and don't necessarily have the same column names from table to table, even within a single year's page.\n",
    "4. Occasionally there is a typo in the table. An empty cell may not have been coded in, or an extra cell may be unintentionally present in one row. As Wikipedia is crowd-edited, these errors may randomly pop up and go away as edits are made.\n",
    "\n",
    "\n",
    "## 1. Generalities on web crawling tables\n",
    "\n",
    "A webpage is basically a tree with nodes labeled by tags. `BeautifulSoup` packages this tree in an object that is easy to navigate and search, based off of the html tags attached to the nodes. Here's how we are going to pull the movie data for any given year.\n",
    "1. We pull the raw html using a `GET` request. It is generally frowned upon to make many requests to a website in a short period of time. For us this means that a request may be denied if too many are made too quickly. So, after each page we should pause for a moment.\n",
    "2. Dump the html into a `BeautifulSoup` object.\n",
    "3. From inspecting the raw html it looks like the data we want is always in a table, which we can find with the `<table>` tag. There are some other tables, such as the footers and page navigation that we don't want. Again from inspection, it looks like the tables we do want always have a `class=wikitable` attribute.\n",
    "4. The tables are then split into table rows, as indicated by a `<tr>` tag.. A row either consitsts of headers (`<th>` table header tag) or data (`<td>` table data tag), or a combination of the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "#find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pulling from tables\n",
    "\n",
    "As each Wikipedia film page generallhy has the data seperated into several tables, the first step is to make a function that can process a single table. For prototyping we take a sample of a (portion of) one of the tables we are interested in parsing. \n",
    "\n",
    "(Aside: For some reason I got it into my head that it is bad practice to use docstrings for long, multiline strings because they are meant for documentation purposes. I'm only using them here because, well, prototyping. Also, I can't justify why using docstrings as strings is actually bad practice.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<table>\n",
    "<tr><th colspan=\"2\">Opening</th>\n",
    "  <th style=\"width:20%;\">Title</th>\n",
    "  <th style=\"width:10%;\">Director</th>\n",
    "  <th>Cast</th>\n",
    "  <th style=\"width:13%\">Genre</th>\n",
    "  <th style=\"width:20%\">Notes</th>\n",
    "  <th>Ref.</th>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "  <th rowspan=\"22\"><b>J<br />A<br />N<br />U<br />A<br />R<br />Y<br /></b></th>\n",
    "  <th><b>2</b></th>\n",
    "  <td><i><a href=\"/wiki/The_Woman_in_Black_2:_Angel_of_Death\" class=\"mw-redirect\" title=\"The Woman in Black 2: Angel of Death\">The Woman in Black 2: Angel of Death</a></i></td>\n",
    "  <td><a href=\"/wiki/Tom_Harper_(director)\" title=\"Tom Harper (director)\">Tom Harper</a></td>\n",
    "  <td><a href=\"/wiki/Phoebe_Fox\" title=\"Phoebe Fox\">Phoebe Fox</a><p><a href=\"/wiki/Jeremy_Irvine\" title=\"Jeremy Irvine\">Jeremy Irvine</a></p><p><a href=\"/wiki/Helen_McCrory\" title=\"Helen McCrory\">Helen McCrory</a></p><p><a href=\"/wiki/Adrian_Rawlins\" title=\"Adrian Rawlins\">Adrian Rawlins</a></p><p><a href=\"/wiki/Ned_Dennehy\" title=\"Ned Dennehy\">Ned Dennehy</a></p></td>\n",
    "  <td><a href=\"/wiki/Horror_film\" title=\"Horror film\">Horror</a></td>\n",
    "  <td><a href=\"/wiki/Relativity_Media\" title=\"Relativity Media\">Relativity Media</a><p>Sequel to <i><a href=\"/wiki/The_Woman_in_Black_(2012_film)\" title=\"The Woman in Black (2012 film)\">The Woman in Black (2012)</a></i></p></td>\n",
    "  <td></td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "  <th rowspan=\"2\"><b>9</b></th> \n",
    "  <td><i><a href=\"/wiki/Taken_3\" title=\"Taken 3\">Taken 3</a></i></td>\n",
    "  <td><a href=\"/wiki/Olivier_Megaton\" title=\"Olivier Megaton\">Olivier Megaton</a></td>\n",
    "  <td><a href=\"/wiki/Liam_Neeson\" title=\"Liam Neeson\">Liam Neeson</a><p><a href=\"/wiki/Forest_Whitaker\" title=\"Forest Whitaker\">Forest Whitaker</a></p><p><a href=\"/wiki/Famke_Janssen\" title=\"Famke Janssen\">Famke Janssen</a></p><p><a href=\"/wiki/Maggie_Grace\" title=\"Maggie Grace\">Maggie Grace</a></p></td>\n",
    "  <td><a href=\"/wiki/Action_film\" title=\"Action film\">Action</a></td>\n",
    "  <td><a href=\"/wiki/20th_Century_Fox\" title=\"20th Century Fox\">20th Century Fox</a></td>\n",
    "  <td></td>\n",
    "</tr>\n",
    "</table>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# Get a table to work with\n",
    "tables = soup.find_all('table') #, {'class': 'wikitable'})\n",
    "table = tables[0]\n",
    "\n",
    "# Get all rows from table, i.e., all <tr> tags\n",
    "rows = table.find_all('tr')\n",
    "\n",
    "# row of headers\n",
    "row0 = rows[0]\n",
    "# row with awkward month column\n",
    "row1 = rows[1]\n",
    "# row with awkward day column\n",
    "row2 = rows[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fun fact.** For some reason in Jupyter when operations are ran multiple times on BeautifulSoup Tag objects, the attributes are getting stripped and causing errors on repeated runs. I should look into why this is.\n",
    "\n",
    "### 2.1. Processing table headers\n",
    "\n",
    "A naive approach to finding the headers in a table would be to find all `<th>` tags, and then collect them. However, some headers have a `colspan` attribute which makes the column span multiple cells of a row. \n",
    "Our code will need a way of dealing with these multicolumn. The approach we will take is to treat each cell spanned by a multicolumn as its own column, but add a suffix to indicate that columns are connected. In the example html, the `Opening` header has a colspan of 2, so we will make two columns `Opening__0` and `Opening__1`. (The `__` chosen to be unlikely to occur in the wild.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opening__0',\n",
       " 'Opening__1',\n",
       " 'Title',\n",
       " 'Director',\n",
       " 'Cast',\n",
       " 'Genre',\n",
       " 'Notes',\n",
       " 'Ref.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if row is a header row and if so, build the columns.\n",
    "# Should be refactored to be more pythonic?\n",
    "# I Want list comprehensions...\n",
    "def parse_header_row(row):\n",
    "    # If exists <td> tags then not a header row\n",
    "    if row.find_all('td'):\n",
    "        raise ValueError(\"`row` is not a table header.\")\n",
    "    \n",
    "    columns = []\n",
    "    for x in row.find_all('th'):\n",
    "        colspan = int(x.attrs.pop('colspan', 1))\n",
    "        if colspan > 1:\n",
    "            columns += [f'{x.text.strip()}__{i}' for i in range(colspan)]\n",
    "        else:\n",
    "            columns += [x.text.strip()]\n",
    "    return columns\n",
    "\n",
    "columns = parse_header_row(row0)\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Processing rows\n",
    "\n",
    "Again, simply finding all the `<td>` tags in a row for the data is too naive. The first issue is that there are multirows where a single value is spread over cells in multiple rows of the table. The second issue is that some tables have typos and a cell in a row is not coded. To deal with these issues, we will take the column of the table as an immutable specification of how many cells there should be per row. \n",
    "\n",
    "To deal with multirows, we will need a `counter` which propagates values from earlier in the table for however many rows as specified by a multirow attribute when encountered. If a row is having values propagated to it from earlier in the table, it will have fewer `<td>` tags than expected. If a row has multiple cells with values being propogated, then the mapping between cell number and data tags is not direct (though it is monotonic). We will deal with this by incrementing over the table row only when a value is not propagated using a `cell_cursor`.\n",
    "\n",
    "Most missing or extra data cells only occur at the end of a row, as anywhere else would cause the cells of the row to be misaligned with the headers and more easily seen by editors of the page. So, we can also deal the missing cell issue by filling in the rest of the cells of a row with `None` after the `cell_cursor` has reached the end of the table row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Again, there has to be a more elegant way to do this...\n",
    "def parse_data_row(row, columns, counters):\n",
    "    cells = row.find_all(['th', 'td'])\n",
    "    cell_cursor = 0\n",
    "    row_processed = []\n",
    "\n",
    "    for col in columns:\n",
    "\n",
    "        # Check if values to propagate\n",
    "        if counters[col][0] > 0:\n",
    "            cell_value = counters[col][1]\n",
    "            counters[col][0] -= 1   \n",
    "        # If not propagate, get from cell    \n",
    "        elif cell_cursor < len(cells):\n",
    "            cell = cells[cell_cursor]\n",
    "            rowspan = int(cell.attrs.pop('rowspan', 1))\n",
    "            cell_value = cell.text.strip()\n",
    "\n",
    "            if rowspan > 1:\n",
    "                counters[col] = [rowspan - 1, cell_value]\n",
    "\n",
    "            cell_cursor += 1\n",
    "        else:\n",
    "            cell_value = None\n",
    "\n",
    "        row_processed.append(cell_value)     \n",
    "        \n",
    "    return row_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the counters are behaving correctly. Notice the values of the `Opening__0` and `Opening__1` cells where multirows are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial counters:\n",
      "{'Opening__0': [0, None], 'Opening__1': [0, None], 'Title': [0, None], 'Director': [0, None], 'Cast': [0, None], 'Genre': [0, None], 'Notes': [0, None], 'Ref.': [0, None]}\n",
      "\n",
      "parsed row:\n",
      "['JANUARY', '2', 'The Woman in Black 2: Angel of Death', 'Tom Harper', 'Phoebe FoxJeremy IrvineHelen McCroryAdrian RawlinsNed Dennehy', 'Horror', 'Relativity MediaSequel to The Woman in Black (2012)', '']\n",
      "\n",
      "counters:\n",
      "{'Opening__0': [21, 'JANUARY'], 'Opening__1': [0, None], 'Title': [0, None], 'Director': [0, None], 'Cast': [0, None], 'Genre': [0, None], 'Notes': [0, None], 'Ref.': [0, None]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For entries with rowspan, save value and amount left to fill\n",
    "counters = dict((key, [0, None]) for key in columns)\n",
    "\n",
    "print('initial counters:', counters, '', sep='\\n')\n",
    "parsed1 = parse_data_row(row1, columns, counters)\n",
    "\n",
    "print('parsed row:', parsed1, '', sep='\\n')\n",
    "print('counters:', counters, '', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed row:\n",
      "['JANUARY', '9', 'Taken 3', 'Olivier Megaton', 'Liam NeesonForest WhitakerFamke JanssenMaggie Grace', 'Action', '20th Century Fox', '']\n",
      "\n",
      "counters:\n",
      "{'Opening__0': [20, 'JANUARY'], 'Opening__1': [1, '9'], 'Title': [0, None], 'Director': [0, None], 'Cast': [0, None], 'Genre': [0, None], 'Notes': [0, None], 'Ref.': [0, None]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed2 = parse_data_row(row2, columns, counters)\n",
    "print('parsed row:', parsed2, '', sep='\\n')\n",
    "print('counters:', counters, '', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `text` attribute in BeautifulSoup strips tags like `<br />` which should possibly be interpreted as `\\n` characters, or some other divider. For now we will just ignore this. The only place this really matters is with the \"Cast\" columns, where it is clumping together actor names.\n",
    "\n",
    "### 2.3. Parsing whole table\n",
    "\n",
    "Parsing the entire table is just a matter of parsing the headers, setting up the counters, and iterating over all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_table(table):\n",
    "    \"\"\"Parse rows of table.\"\"\"\n",
    "    rows = table.find_all('tr')\n",
    "\n",
    "    header_row = rows.pop(0)\n",
    "    columns = parse_header_row(header_row) \n",
    "    # For entries with rowspan, save value and amount left to fill        \n",
    "    counters = dict((key, [0, None]) for key in columns)\n",
    "    \n",
    "    table_parsed = []\n",
    "    for row in rows:\n",
    "        row_parsed = parse_data_row(row, columns, counters)\n",
    "        table_parsed.append(row_parsed)\n",
    "        \n",
    "    table_parsed = pd.DataFrame(table_parsed, columns=columns)\n",
    "    return table_parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opening__0</th>\n",
       "      <th>Opening__1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Ref.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>2</td>\n",
       "      <td>The Woman in Black 2: Angel of Death</td>\n",
       "      <td>Tom Harper</td>\n",
       "      <td>Phoebe Fox\\nJeremy Irvine\\nHelen McCrory\\nAdri...</td>\n",
       "      <td>Horror</td>\n",
       "      <td>Relativity Media\\nSequel to The Woman in Black...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>9</td>\n",
       "      <td>Taken 3</td>\n",
       "      <td>Olivier Megaton</td>\n",
       "      <td>Liam Neeson\\nForest Whitaker\\nFamke Janssen\\nM...</td>\n",
       "      <td>Action</td>\n",
       "      <td>20th Century Fox</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>9</td>\n",
       "      <td>Let's Kill Ward's Wife</td>\n",
       "      <td>Scott Foley</td>\n",
       "      <td>Scott FoleyPatrick WilsonDonald FaisonJames Ca...</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Well Go USA Entertainment</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>14</td>\n",
       "      <td>Match</td>\n",
       "      <td>Stephen Belber</td>\n",
       "      <td>Patrick StewartCarla GuginoMatthew LillardRob ...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>IFC Films</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JANUARY</td>\n",
       "      <td>16</td>\n",
       "      <td>Blackhat</td>\n",
       "      <td>Michael Mann</td>\n",
       "      <td>Chris HemsworthViola DavisManny MontanaTang Wei</td>\n",
       "      <td>Action</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Opening__0 Opening__1                                 Title  \\\n",
       "0    JANUARY          2  The Woman in Black 2: Angel of Death   \n",
       "1    JANUARY          9                               Taken 3   \n",
       "2    JANUARY          9                Let's Kill Ward's Wife   \n",
       "3    JANUARY         14                                 Match   \n",
       "4    JANUARY         16                              Blackhat   \n",
       "\n",
       "          Director                                               Cast   Genre  \\\n",
       "0       Tom Harper  Phoebe Fox\\nJeremy Irvine\\nHelen McCrory\\nAdri...  Horror   \n",
       "1  Olivier Megaton  Liam Neeson\\nForest Whitaker\\nFamke Janssen\\nM...  Action   \n",
       "2      Scott Foley  Scott FoleyPatrick WilsonDonald FaisonJames Ca...  Comedy   \n",
       "3   Stephen Belber  Patrick StewartCarla GuginoMatthew LillardRob ...   Drama   \n",
       "4     Michael Mann    Chris HemsworthViola DavisManny MontanaTang Wei  Action   \n",
       "\n",
       "                                               Notes  Ref.  \n",
       "0  Relativity Media\\nSequel to The Woman in Black...        \n",
       "1                                   20th Century Fox        \n",
       "2                          Well Go USA Entertainment  [11]  \n",
       "3                                          IFC Films  [12]  \n",
       "4                                 Universal Pictures  [13]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f'https://en.wikipedia.org/wiki/List_of_American_films_of_2015'\n",
    "# Get raw html\n",
    "response = requests.get(url)  \n",
    "# Soupify\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Get a table to work with\n",
    "tables = soup.find_all('table', {'class': 'wikitable'})\n",
    "table = tables[0]\n",
    "\n",
    "parse_table(table).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Next steps\n",
    "\n",
    "There are a few odds and ends that ended up in the final script for this portion of the project not mentioned here.\n",
    "\n",
    "\n",
    "### 3.1. Cells with too much information\n",
    "\n",
    "The `text` attribute in BeautifulSoup is perhaps too aggressive in stripping tags from text fields, and leaving us with the concatenated \"Cast\" names above. A more cautious approach would be to leave a marker where tags were stripped, and deal with them later. This may be more practiable, as different columns would need to be handled separately, which would be assuming too much structure from table to table on Wikipedia. For example in the `List_of_American_films_of_2015` table the `<br \\>` tags seperate actors in the \"Cast\" column, but spread out a note over multiple lines in the \"Notes\" column. \n",
    "\n",
    "There is a `stripped_strings` attribute in BeautifulSoup which returns a generator of the text which we can then for example join with whatever seperator we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = table.find_all('tr')\n",
    "row4 = rows[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scott Foley', 'Patrick Wilson', 'Donald Faison', 'James Carpinello']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_column = row4.find_all('td')[2]\n",
    "[string for string in cast_column.stripped_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scott Foley|Patrick Wilson|Donald Faison|James Carpinello'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'|'.join(cast_column.stripped_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Crawling a full page\n",
    "\n",
    "Each page typically has multiple tables. Unfortunately, even on a single page not all the tables have the same column header names. This causes Pandas to add extra columns when we append multiple data frames together from the tables from a single page. Specifically, the 1962 page has a \"Notes/Studio\" column in the first table which is renamed to just \"Notes\" in all subsequent tables. The solution we went with was to take the columns from the first table on a page as master, and force all subsequent tables to have the same column names. Another option would to just let Pandas do its thing, and deal with this later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
